Documentation Source:
airbyte.com/tutorials/creating-duckdb-destination-with-python.html

Documentation Title:
How to Create an Airbyte Python Destination: DuckDB | Airbyte

Documentation Content:
:param logger: Logging object to display debug/info/error to the logs
            (logs will not be accessible via airbyte UI if they are not passed to this logger)
        :param config: Json object containing the configuration of this destination, content of this json is as specified in
        the properties of the spec.json file

        :return: AirbyteConnectionStatus indicating a Success or Failure</code><p>The way we can achieve that is by checking the input `config` parameters and setting up a connection to the database. If all parameters are ok and the connection establishes, we return the `Status.SUCCEEDED`.</p><strong>Function write()</strong><p>The write function reads the data passed from the source connector to our destination. You can see below in the function definition that we get a list of<a>Airbyte Messages</a>. This is important to know as Airbyte serialized data into JSON Messages, making it possible to convert any source to any destination.</p><p>We also get the<a>ConfiguredAirbyteCatalog</a>, which describes the schema of the messages and how it's persisted in the destination.</p><code>def write(
        self, config: Mapping[str, Any], configured_catalog: ConfiguredAirbyteCatalog, input_messages: Iterable[AirbyteMessage]
    ) -&gt; Iterable[AirbyteMessage]:

        """
        Reads the input stream of messages, config, and catalog to write data to the destination.

        This method returns an iterable (typically a generator of AirbyteMessages via yield) containing state messages received in the input message stream. Outputting a state message means that every AirbyteRecordMessage which came before it has been successfully persisted to the destination. This is used to ensure fault tolerance in the case that a sync fails before fully completing, then the source is given the last state message output from this method as the starting point of the next sync.



Documentation Source:
airbyte.com/docs.airbyte.com/connector-development/config-based/tutorial/connecting-to-the-API-source.html

Documentation Title:
Step 3: Connecting to the API | Airbyte Documentation

Documentation Content:
It describes what data is available in a source</li><li><code>source-exchange-rates-tutorial/integration_tests/sample_state.json</code>: This is a sample state object to be used to test <a>incremental syncs</a>.</li></ul><p>We'll also be creating the following files:</p><ul><li><code>source-exchange-rates-tutorial/secrets/config.json</code>: This is the configuration file we'll be using to test the connector. Its schema should match the schema defined in the spec file.</li><li><code>source-exchange-rates-tutorial/secrets/invalid_config.json</code>: This is an invalid configuration file we'll be using to test the connector. Its schema should match the schema defined in the spec file.</li><li><code>source_exchange_rates_tutorial/schemas/rates.json</code>: This is the <a>schema definition</a>for the stream we'll implement.</li></ul><h2>Updating the connector spec and config<a>​</a></h2><p>Let's populate the specification (<code>spec</code>) and the configuration (<code>secrets/config.json</code>) so the connector can access the access key and base currency.</p><li>We'll add these properties to the <code>spec</code>block in the <code>source-exchange-rates-tutorial/source_exchange_rates_tutorial/manifest.yaml</code></li><code><span><span>spec</span><span>:</span></span><span><span>documentation_url</span><span>:</span><span>https</span><span>:</span><span>//docs.airbyte.com/integrations/sources/exchangeratesapi</span></span><span><span>connection_specification</span><span>:</span></span><span><span>$schema</span><span>:</span><span>http</span><span>:</span><span>//json</span><span>-</span><span>schema.org/draft</span><span>-</span><span>07/schema</span><span>#</span></span><span><span>title</span><span>:</span><span>exchangeratesapi.



Documentation Source:
airbyte.com/tutorials/extract-data-from-the-webflow-api.html

Documentation Title:
Build a connector to extract data from the Webflow API | Airbyte

Documentation Content:
Go to <em>Settings → Sources  → + New connector</em>as shown below.</p><p>‍</p><img/><p>‍</p><p>From here you should be able to enter in the information about the docker container that you created as shown in the pop-up below, and by then pressing the <em>Add</em>button. </p><p>‍</p><img/><p>‍</p><p>You should now be able to create a new <em>connection</em>(source connector + destination connector) that uses your Webflow source connector, by clicking in the UI as demonstrated below:</p><p>‍</p><img/><p>‍</p><p>Select the Webflow connector that you created as follows. </p><img/><p>And from there you will be requested to enter in the <em>Site id</em>and <em>API token</em>as follows: </p><p>‍</p><img/><p>Once the source has been created you will be asked to select a destination. You may wish to export Webflow data to a <a>local CSV file</a>, backup Webflow data into <a>S3</a>, or extract Webflow data to send into <a>BigQuery</a>, etc. – the list of <a>supported destinations</a>is long and growing. </p><p>Below I show how to replicate Webflow collections to a <a>local json file</a>.</p><img/><p>‍</p><p>This tells Airbyte to output json data to <em>/tmp/airbyte_local/webflow-blog-test</em>. You will then be presented with a screen that allows you to configure the connection parameters as follows:</p><img/><p>Notice that there are many stream names available, all of which were <strong>dynamically generated based on the collections that are available in Webflow</strong>. Using the switch on the left side allows you to specify which of these streams you are interested in replicating to your output.



Documentation Source:
airbyte.com/docs.airbyte.com/operator-guides/configuring-connector-resources.html

Documentation Title:
Configuring Connector Resources | Airbyte Documentation

Documentation Content:
If the url is <code>localhost:8000/workspaces/92ad8c0e-d204-4bb4-9c9e-30fe25614eee/connections/5432b428-b04a-4562-a12b-21c7b9e8b63a/status</code>,
the connection id is <code>5432b428-b04a-4562-a12b-21c7b9e8b63a</code>.</li></li><li>Connect to the database and run the following command with the connection id and resource requirements filled in.</li></ol><code><span>// SQL command with example</span><span><span>update</span><span>connection </span><span>set</span><span>resource_requirements </span><span>=</span><span>'{"cpu_limit": "0.5", "cpu_request": "0.5", "memory_limit": "500Mi", "memory_request": "500Mi"}'</span><span>where</span><span>id </span><span>=</span><span>'&lt;id-from-step-1&gt;'</span><span>;</span></span></code><h2>Debugging Connection Resources<a>​</a></h2><p>Airbyte logs the resource requirements as part of the job logs as containers are created.



