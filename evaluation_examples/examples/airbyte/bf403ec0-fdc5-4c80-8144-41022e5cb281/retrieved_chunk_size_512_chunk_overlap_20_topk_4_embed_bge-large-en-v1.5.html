Documentation Source:
airbyte.com/tutorials/incremental-data-synchronization.html

Documentation Title:
Incremental data synchronization between Postgres databases | Airbyte

Documentation Content:
If you wish to view this database for yourself, you can login to it as follows: </p><code>docker exec -ti airbyte-db psql -U docker -d airbyte</code><p>The contents of the state database can be viewed with the following command: </p><code>SELECT * FROM state;</code><p>Which should respond with a table similar to the one given below (note that the response is abbreviated in this article for conciseness): </p><code>id                  |            connection_id             |                                                                                                  state                                                                   |          created_at           |          updated_at           | stream_name | namespace |  type  
--------------------------------------+--------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------+-------------------------------+-------------+-----------+--------
 884a10a7-1c58-4456-af44-c617eec0c1fb | 78cb42b9-e857-4f93-b159-e590ec31d287 | {"state": {"cdc": false, "streams": [{"cursor": "2022-09-02T07:55:58.324989", "stream_name": "table_one", "cursor_field": ["updated_at"], "stream_namespace": "public"}]}} | 2022-09-01 16:52:44.619871+00 | 2022-09-02 07:59:27.304753+00 |             |           | LEGACY
</code><h3>Why and when is a primary key required</h3><p>Records that are inserted <em>or updated</em>on a source system are replicated by Airbyte to the destination during a sync operation, and initially stored in a raw data table. If a given document is updated and synchronized multiple times, the raw data table will have multiple entries for that record (as will be seen in the hands-on deep-dive later in this article). </p><p>If an Airbyte user has selected the Incremental Sync - Deduped History sync mode, then the data must be deduplicated so that a single entry in the source table only results in a single corresponding entry in the final normalized deduplicated destination table, even though multiple versions corresponding to that record may appear in the raw and historic data tables.



Documentation Source:
airbyte.com/tutorials/full-data-synchronization.html

Documentation Title:
Explore Airbyte's full refresh data synchronization | Airbyte

Documentation Content:
This is easiest to see for yourself via a hands-on example, as presented below.</p><h3>Create a full refresh append connection</h3><p>Set up a new connection that will demonstrate <strong>full refresh | append</strong>functionality, using the connectors that you created earlier in this tutorial.</p><p>First, select <strong>Postgres-source</strong>as the source for this connection.</p><img/><p>‍</p><p>Then select <strong>Postgres-destination </strong>as the destination for this connection.</p><img/><p>‍</p><p>Then create a new connection and name it <strong>full-refresh-append</strong>, set the prefix to <strong>append</strong>_ ,and select <strong>full refresh | append</strong>as the sync mode, as shown below.</p><img/><p>A sync should automatically start after you create the connection. Wait for the sync to complete, and you should see a message like the following: </p><p>‍</p><img/><h3>Open a Postgres terminal on the destination</h3><p>If you don’t already have a shell open to your Postgres destination, execute the following commands:</p><code>docker exec -it airbyte-destination /bin/bash
psql --username=postgres
</code><p>‍</p><p>You can view the tables in the destination Postgres database by executing the following command from the Postgres shell that you have just opened .



Documentation Source:
airbyte.com/tutorials/full-data-synchronization.html

Documentation Title:
Explore Airbyte's full refresh data synchronization | Airbyte

Documentation Content:
Execute the following command to open a shell to the destination Postgres database:</p><code>docker exec -it airbyte-destination /bin/bashpsql --username=postgres
psql --username=postgres
</code><h3>Look at the data in the Postgres destination</h3><p>You can view the tables in the destination Postgres database by executing the following command from the Postgres shell that you have just opened . </p><code>\dt;
</code><p>‍</p><p>Which should respond with the following: </p><code>List of relations
 Schema |                   Name                   | Type  |  Owner   
--------+------------------------------------------+-------+----------
 public | _airbyte_raw_overwrite_full_refresh_demo | table | postgres
 public | overwrite_full_refresh_demo              | table | postgres
(2 rows)
</code><p>‍</p><blockquote>ℹ️  Notice that there are two tables. As discussed earlier, Airbyte converts each source record into a JSON blob that contains all of your data, and writes it into the <strong>_airbyte_raw_overwrite_full_refresh_demo</strong>table.



Documentation Source:
airbyte.com/tutorials/postgres-replication.html

Documentation Title:
Postgres Replication: Data Transfer Efficiency | Airbyte

Documentation Content:
Let's dive into using Airbyte for PostgreSQL <a>CDC</a>.</p><h2>Prerequisites</h2><ul><li>Having <a>Docker</a>and <a>Docker Compose</a>installed.</li><li><a>Deploying Airbyte</a>.</li></ul></div><h2>Step 1: Set up your source Postgres database (optional)</h2><div><p>If you don’t have a readily available Postgres database to sync, here are some quick instructions. Run the following commands in a new terminal window to start backgrounded source and destination databases:</p><code>docker run --rm --name airbyte-source -e POSTGRES_PASSWORD=password -p 2000:5432 -d postgres
docker run --rm --name airbyte-destination -e POSTGRES_PASSWORD=password -p 3000:5432 -d postgres
</code><p>Add two tables with a few rows to the source database:</p><code>docker exec -it airbyte-source psql -U postgres -c "CREATE TABLE users(id SERIAL PRIMARY KEY, col1 VARCHAR(200));"
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.users(col1) VALUES('record1');"
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.users(col1) VALUES('record2');"
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.users(col1) VALUES('record3');"

docker exec -it airbyte-source psql -U postgres -c "CREATE TABLE cities(city_code VARCHAR(8), city VARCHAR(200));"
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.cities(city_code, city) VALUES('BCN', 'Barcelona');"
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.cities(city_code, city) VALUES('MAD', 'Madrid');"   
docker exec -it airbyte-source psql -U postgres -c "INSERT INTO public.cities(city_code, city) VALUES('VAL', 'Valencia');"
</code><p>You now have a Postgres database ready to be replicated.



