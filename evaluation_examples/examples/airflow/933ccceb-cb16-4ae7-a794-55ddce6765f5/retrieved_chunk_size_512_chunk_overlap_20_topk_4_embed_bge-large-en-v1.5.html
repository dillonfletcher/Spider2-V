Documentation Source:
docs.astronomer.io/learn/airflow-sql-data-quality.html

Documentation Title:
Run data quality checks using SQL check operators | Astronomer Documentation

Documentation Content:
py</code>.</p><li><p>Copy and paste the following DAG code into the file:</p><code><span>"""</span><span>## Check data quality using SQL check operators</span><span>This DAG creates a toy table about birds in SQLite to run data quality checks on using the </span><span>SQLColumnCheckOperator, SQLTableCheckOperator, and SQLCheckOperator.</span><span>"""</span><span><span>from</span><span>airflow</span><span>.</span><span>decorators </span><span>import</span><span>dag</span></span><span><span>from</span><span>airflow</span><span>.</span><span>providers</span><span>.</span><span>common</span><span>.</span><span>sql</span><span>.</span><span>operators</span><span>.</span><span>sql </span><span>import</span><span>(</span></span><span><span>SQLColumnCheckOperator</span><span>,</span></span><span><span>SQLTableCheckOperator</span><span>,</span></span><span><span>SQLCheckOperator</span><span>,</span></span><span>)</span><span><span>from</span><span>airflow</span><span>.</span><span>providers</span><span>.</span><span>sqlite</span><span>.</span><span>operators</span><span>.</span><span>sqlite </span><span>import</span><span>SqliteOperator</span></span><span><span>from</span><span>pendulum </span><span>import</span><span>datetime</span></span><span><span>_CONN_ID </span><span>=</span><span>"sqlite_conn"</span></span><span><span>_TABLE_NAME </span><span>=</span><span>"birds"</span></span><span><span>@dag</span><span>(</span></span><span><span>start_date</span><span>=</span><span>datetime</span><span>(</span><span>2023</span><span>,



Documentation Source:
docs.astronomer.io/learn/airflow-sql-data-quality.html

Documentation Title:
Run data quality checks using SQL check operators | Astronomer Documentation

Documentation Content:
Note that currently the operators cannot support BigQuery <code>job_id</code>s.</li><li>A love for birds.</li></ul><h2>Step 1: Configure your Astro project<a>​</a></h2><p>To use SQL check operators, install the <a>Common SQL provider</a>in your Astro project.</p><ol><li><p>Run the following commands to create a new Astro project:</p><code><span><span>$ </span><span>mkdir</span><span>astro-sql-check-tutorial </span><span>&amp;&amp;</span><span>cd</span><span>astro-sql-check-tutorial</span></span><span>$ astro dev init</span></code></li><li><p>Add the Common SQL provider and the SQLite provider to your Astro project <code>requirements.txt</code>file.</p><code><span>apache-airflow-providers-common-sql==1.5.2</span><span>apache-airflow-providers-sqlite==3.4.2</span></code></li></ol><h2>Step 2: Create a connection to SQLite<a>​</a></h2><ol><p>In the Airflow UI, go to <strong>Admin</strong>&gt; <strong>Connections</strong>and click <strong>+</strong>.</p><li><p>Create a new connection named <code>sqlite_conn</code>and choose the <code>SQLite</code>connection type. Enter the following information:</p><ul><li><strong>Connection Id</strong>: <code>sqlite_conn</code>.</li><li><strong>Connection Type</strong>: <code>SQLite</code>.</li><li><strong>Host</strong>: <code>/tmp/sqlite.db</code>.</li></ul></li></ol><h2>Step 3: Add a SQL file with a custom check<a>​</a></h2><ol><p>In your <code>include</code>folder, create a file called <code>custom_check.sql</code>.



Documentation Source:
docs.astronomer.io/learn/data-quality.html

Documentation Title:
Data quality and Airflow | Astronomer Documentation

Documentation Content:
Astronomer recommends using SQL check operators if you want to:</p><ul><li>Write checks without needing to set up software in addition to Airflow.</li><li>Write checks as Python dictionaries and in SQL.</li><li>Use any SQL statement that returns a single row of booleans as a data quality check.</li><li>Implement many different downstream dependencies depending on the outcome of different checks.</li><li>Have full observability of which checks failed from within Airflow task logs, including the full SQL statements of failed checks.</li></ul><p>Astronomer recommends using a data validation framework such as Great Expectations or Soda in the following circumstances:</p><ul><li>You want to collect the results of your data quality checks in a central place.</li><li>You prefer to write checks in JSON (Great Expectations) or YAML (Soda).</li><li>Most or all of your checks can be implemented by the predefined checks in the solution of your choice.</li><li>You want to abstract your data quality checks from the DAG code.</li></ul><p>Currently only SQL check operators and the GreatExpectationsOperator offer data lineage extraction through <a>OpenLineage</a>.</p><h3>SQL check operators<a>​</a></h3><div><div>info</div><p>You can find more details and examples using SQL check operators in the <a>Run data quality checks using SQL check operators</a>tutorial.</p></div><p>SQL check operators execute a SQL statement that results in a set of booleans. A result of <code>True</code>leads to the check passing and the task being labeled as successful. A result of <code>False</code>, or any error when the statement is executed, leads to a failure of the task. Before using any of the operators, you need to define the <a>connection</a>to your data storage from the Airflow UI or with an external secrets manager.</p><p>The SQL check operators work with any backend solution that accepts SQL queries and supports Airflow, and differ in what kind of data quality checks they can perform and how they are defined.



Documentation Source:
docs.astronomer.io/learn/airflow-sql-data-quality.html

Documentation Title:
Run data quality checks using SQL check operators | Astronomer Documentation

Documentation Content:
Using this set of operators, you can quickly develop a pipeline specifically for checking data quality, or you can add data quality checks to existing pipelines with just a few more lines of code.</p><p>This tutorial shows how to use three SQL check operators (SQLColumnCheckOperator, SQLTableCheckOperator, and SQLCheckOperator) to build a robust data quality suite for your DAGs.</p><div><div>Other ways to learn</div><div><p>There are multiple resources for learning about this topic. See also:</p><ul><li>Webinar: <a>Implementing Data Quality Checks in Airflow</a>.</li><li>Webinar: <a>Efficient data quality checks with Airflow 2.7</a>.</li><li>Use case: <a>Use Airflow setup/ teardown to run data quality checks in an MLOps pipeline</a>.</li><li>Example repository: <a>data quality demo</a>.</li></ul></div></div><h2>Time to complete<a>​</a></h2><p>This tutorial takes approximately 30 minutes to complete.</p><h2>Assumed knowledge<a>​</a></h2><p>To get the most out of this tutorial, you should have an understanding of:</p><ul><li>How to design a data quality process. See <a>Data quality and Airflow</a>.</li><li>Running SQL from Airflow. See <a>Using Airflow to execute SQL</a>.</li></ul><h2>Prerequisites<a>​</a></h2><ul><li>The <a>Astro CLI</a>.</li><li>Access to a relational database. You can use an in-memory SQLite database for which you'll need to install the <a>SQLite provider</a>.



