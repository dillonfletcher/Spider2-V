I am using Astronomer to deploy Airflow
The verbose instruction is about model training for the machine learning experiments with following detailed steps:
1. Click the VS Code editor on the left panel or dock for the dag file "train.py".
2. First, we call mlflow.sklearn.autolog() to enable automatic logging
'''append code according to where corresponding annotation instructed
mlflow.sklearn.autolog()
'''
3. We implement code to drop rows with missing values
'''append code according to where corresponding annotation instructed
feature_df = feature_df.dropna()
'''
4. We implement code to define the target column and the model
'''append code according to where corresponding annotation instructed
target = target_column
model = model_class(**hyper_parameters)
'''
5. We implement code to start an MLFlow run with mlflow.start_run(), setting the experiment_id and run_name. Use a with statement so the run is automatically closed when done.
'''append code according to where corresponding annotation instructed
with mlflow.start_run(experiment_id=experiment_id, run_name=run_name) as run:
    model.fit(feature_df.drop(target, axis=1), feature_df[target])

run_id = run.info.run_id
'''
6. We implement code to train model "model_trained" with following parameters: feature_df=fetched_feature_df, experiment_id=fetched_experiment_id, target_column=TARGET_COLUMN, model_class=RidgeCV, hyper_parameters={"alphas": np.logspace(-3, 1, num=30)}, run_name="RidgeCV"
'''append code according to where corresponding annotation instructed
train_model(
    feature_df=fetched_feature_df,
    experiment_id=fetched_experiment_id,
    target_column=TARGET_COLUMN,
    model_class=RidgeCV,
    hyper_parameters={"alphas": np.logspace(-3, 1, num=30)},
    run_name="RidgeCV",
)
'''
7. We implement code to create an instance of MLflowClientHook named mlflow_hook, setting mlflow_conn_id and method. Then, use the mlflow_hook.run() method to send a GET request to api/2.0/mlflow/registered-models/get, passing reg_model_name as a request parameter. Convert the response to JSON format and assign it to get_reg_model_response.
'''append code according to where corresponding annotation instructed
mlflow_hook = MLflowClientHook(mlflow_conn_id=MLFLOW_CONN_ID, method="GET")
get_reg_model_response = mlflow_hook.run(
    endpoint="api/2.0/mlflow/registered-models/get",
    request_params={"name": reg_model_name},
).json()
'''
8. We implement code to check if get_reg_model_response contains error_code. If it does, and if error_code is RESOURCE_DOES_NOT_EXIST, set reg_model_exists to False. Otherwise, if error_code is not RESOURCE_DOES_NOT_EXIST, raise a ValueError. If get_reg_model_response does not contain error_code, set reg_model_exists to True.
'''append code according to where corresponding annotation instructed
if "error_code" in get_reg_model_response:
    if get_reg_model_response["error_code"] == "RESOURCE_DOES_NOT_EXIST":
        reg_model_exists = False
    else:
        raise ValueError(
            f"Error when checking if model is registered: {get_reg_model_response['error_code']}"
        )
else:
    reg_model_exists = True
'''
9. We implement code: If reg_model_exists is True, return "register_model.model_already_registered". Otherwise, return "register_model.create_registered_model".
'''append code according to where corresponding annotation instructed
if reg_model_exists:
    return "register_model.model_already_registered"
else:
    return "register_model.create_registered_model"
'''
10. We implement code to create an instance of EmptyOperator named model_already_registered, setting task_id.
'''append code according to where corresponding annotation instructed
model_already_registered = EmptyOperator(task_id="model_already_registered")
'''
11. We implement code to create an instance of CreateRegisteredModelOperator named create_registered_model, setting task_id, name, and dictionary tags: {"key": "model_type", "value": "regression"},{"key": "data", "value": "possum"} .
'''append code according to where corresponding annotation instructed
create_registered_model = CreateRegisteredModelOperator(
            task_id="create_registered_model",
            name=REGISTERED_MODEL_NAME,
            tags=[
                {"key": "model_type", "value": "regression"},
                {"key": "data", "value": "possum"},
            ],
        )
'''
12. We implement code to create an instance of CreateModelVersionOperator named create_model_version, setting task_id = "create_model_version", name = REGISTERED_MODEL_NAME, source = "s3://" + MLFLOW_ARTIFACT_BUCKET + "/" + "{{ ti.xcom_pull(task_ids='train_model') }}", run_id = "{{ ti.xcom_pull(task_ids='train_model') }}", trigger_rule = "none_failed".
'''append code according to where corresponding annotation instructed
create_model_version = CreateModelVersionOperator(
    task_id="create_model_version",
    name=REGISTERED_MODEL_NAME,
    source="s3://"
    + MLFLOW_ARTIFACT_BUCKET
    + "/"
    + "{{ ti.xcom_pull(task_ids='train_model') }}",
    run_id="{{ ti.xcom_pull(task_ids='train_model') }}",
    trigger_rule="none_failed",
)
'''
13. We implement code to create an instance of TransitionModelVersionStageOperator named transition_model, setting task_id = "transition_model", name = REGISTERED_MODEL_NAME, version = "{{ ti.xcom_pull(task_ids='register_model.create_model_version')['model_version']['version'] }}", stage = "Staging", archive_existing_versions = True.
'''append code according to where corresponding annotation instructed
transition_model = TransitionModelVersionStageOperator(
    task_id="transition_model",
    name=REGISTERED_MODEL_NAME,
    version="{{ ti.xcom_pull(task_ids='register_model.create_model_version')['model_version']['version'] }}",
    stage="Staging",
    archive_existing_versions=True,
)
'''
14. Save the file content and switch to the opened ‘/home/user/projects/mlflow’ terminal.
15. In the terminal, type in the following command to restart the UI:
`astro dev restart` 
16. Click the Chromium on the left pannel
17. On the Airflow web page, find "feature_eng" in the DAG list and click the slider to the left of the name to Unpause dag; 
18. On the Airflow web page, find "train" in the DAG list and click the slider to the left of the name to Unpause dag; 
19. Click the triangle under the Action column on the far right of the "feature_eng" row to trigger the dag and start the pipeline; 
20. Wait until the status of all tasks in the 'Runs' column to change to "success" or "failed", we shall see the first run is failed;
21. Click the triangle just as step 18 instructed.
22. Wait until the status of all tasks in the 'Runs' column to change to "success" or "failed".

