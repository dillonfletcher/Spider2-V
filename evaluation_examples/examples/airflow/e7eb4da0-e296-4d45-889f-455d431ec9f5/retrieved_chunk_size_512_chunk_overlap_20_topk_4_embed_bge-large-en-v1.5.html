Documentation Source:
docs.astronomer.io/learn/logging.html

Documentation Title:
Airflow logging | Astronomer Documentation

Documentation Content:
To view task logs directly in your terminal, run <code>astro dev run tasks test &lt;dag_id&gt; &lt;task_id&gt;</code>with the <a>Astro CLI</a>or <code>airflow tasks test &lt;dag_id&gt; &lt;task_id&gt;</code>if you are running Airflow with other tools.</li><li>Metadata database: Logs are handled differently depending on which database you use.</li></ul><h3>Docker Airflow environment<a>​</a></h3><p>If you run Airflow in Docker using the <a>Astro CLI</a>or by <a>following the Airflow documentation</a>, you can find the logs for each Airflow component in the following locations:</p><ul><li>Scheduler: Logs are in <code>/usr/local/airflow/logs/scheduler</code>within the scheduler Docker container by default. To enter a docker container in a bash session, run <code>docker exec -it &lt;container_id&gt; /bin/bash</code>.</li><li>Webserver: Logs appear in the console by default. You can access the logs by running <code>docker logs &lt;webserver_container_id&gt;</code>.</li><li>Metadata database: Logs appear in the console by default. You can access the logs by running <code>docker logs &lt;postgres_container_id&gt;</code>.</li><li>Triggerer: Logs appear in the console by default. You can access the logs by running <code>docker logs &lt;triggerer_container_id&gt;</code>. Individual triggers' log messages can be found in the logs of tasks that use deferrable operators.</li><li>Task: Logs appear in <code>/usr/local/airflow/logs/</code>within the scheduler Docker container. To access task logs in the Airflow UI click on the square of a task instance in the Grid views and then select the <strong>Logs</strong>tab.</li></ul><img/><p>The Astro CLI includes a command to show webserver, scheduler, triggerer and Celery worker logs from the local Airflow environment.



Documentation Source:
docs.astronomer.io/learn/airflow-ui.html

Documentation Title:
An introduction to the Airflow UI | Astronomer Documentation

Documentation Content:
Here you can find information like total historic runs of a DAG, the data interval start of a DAG run, and the duration of a task instance.</p><p>To access the details of a specific DAG run or task instance, you need first need to select it in the DAG grid as shown in the following gif:</p><img/><p>When you select a task instance in the DAG grid, three additional options appear underneath the tabs:</p><img/><ul><li><strong>More Details:</strong>Shows all attributes of a task, including variables and templates.</li><li><strong>Rendered Template:</strong>Shows the task's metadata after it has been templated.</li><li><strong>List Instances, all runs:</strong>Shows a historical view of task instances and statuses for that particular task.</li></ul><h3>Graph<a>​</a></h3><p>The <strong>Graph</strong>tab shows a  graph visualization of the tasks and dependencies in your DAG, including <a>Airflow datasets</a>a DAG is scheduled on or updates. If you select a task or task group instance in a DAG grid column, the graph highlights and zooms to the selected task. You can also navigate complex DAGs using <strong>Filter Tasks</strong>option and the minimap. This view is useful to explore the DAG structure and task dependencies.</p><img/><div><div>note</div><p>Earlier Airflow versions had a different <strong>Graph</strong>view that was not integrated into the DAG view. See the <a>Airflow documentation of your version</a>for more information.</p></div><h3>Code<a>​</a></h3><p>Under the <strong>Code</strong>tab you can access the code that generates the DAG you are viewing. While your code should live in source control, the <strong>Code</strong>tab provides a quick insight into what is going on in the DAG. DAG code can't be edited in the UI.</p><img/><p>This tab shows code only from the file that generated the DAG.



Documentation Source:
docs.astronomer.io/astro/view-logs.html

Documentation Title:
View Deployment logs | Astronomer Documentation

Documentation Content:
task logs might also be associated with one of the following log levels, that you can search or filter with:</p><ul><strong>Error</strong><strong>Warn</strong><strong>Info</strong><strong>Debug</strong><strong>Critical</strong></ul><h3>View task logs on the Astro UI<a>​</a></h3><p>To access task logs from the Astro UI:</p><ol><li>In the Astro UI, select a Workspace.</li><li>Click <strong>DAGs</strong>.</li><li>Click the DAG you want to view task logs for.</li><li>Click a task run in the DAG run grid.</li><li>Click the <strong>Logs</strong>tab to switch from <strong>Graph</strong>view.</li></ol><h3>View task logs in the Airflow UI<a>​</a></h3><li>Access the Airflow UI.</li><ul><li>To access the Airflow UI for a Deployment, open the Deployment in the Astro UI and click <strong>Open Airflow</strong>.</li><li>To access the Airflow UI in a local environment, open a browser and go to <code>http://localhost:8080</code>.</li></ul><ol><li>Click a DAG.</li><li>Click <strong>Graph</strong>.</li><li>Click a task run.</li><li>Click <strong>Instance Details</strong>.</li><li>Click <strong>Log</strong>.</li></ol><h2>See also<a>​</a></h2><ul><a>Export task logs and metrics to Datadog</a><a>Export task logs to AWS Cloudwatch</a></ul></div><div><h2>Was this page helpful?</h2><div><button>Yes</button><button>No</button></div></div><form><h2>Sign up for Developer Updates</h2><p>Get a summary of new Astro features once a month.</p><button>Submit</button><p>You can unsubscribe at any time.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow.html

Documentation Title:
Get started with Apache Airflow, Part 1: Write and run your first DAG | Astronomer Documentation

Documentation Content:
dag_id=my_astronauts_dag, task_id=print_num_people_in_space, execution_date=20240227T135707, start_date=20240227T135707, end_date=20240227T135707</span></code><p>Repeat steps 1-3 for the <code>print_reaction</code>task. The task logs should include the output of the <code>bash_command</code>given to the task and look similar to the text below:</p><code><span>[2024-02-27, 13:57:08 UTC] {subprocess.py:63} INFO - Tmp dir root location: /tmp</span><span>[2024-02-27, 13:57:08 UTC] {subprocess.py:75} INFO - Running command: ['/bin/bash', '-c', 'echo This is awesome!']</span><span>[2024-02-27, 13:57:08 UTC] {subprocess.py:86} INFO - Output:</span><span>[2024-02-27, 13:57:08 UTC] {subprocess.py:93} INFO - This is awesome!</span><span>[2024-02-27, 13:57:08 UTC] {subprocess.py:97} INFO - Command exited with return code 0</span></code><h2>Next steps<a>​</a></h2><p>Congratulations! You've written and run your first DAG in Airflow. You've also learned how to navigate the Airflow UI and view task logs.



