Documentation Source:
docs.astronomer.io/astro/first-dag-cli.html

Documentation Title:
Run your first DAG with the Astro CLI | Astronomer Documentation

Documentation Content:
See:</p><ul><li><a>Develop a project</a>.</li><li><a>Install Docker</a>to use the full capabilities of the Astro CLI, such as the ability to run Airflow locally and deploy the rest of your Astro project to Astro, including Python packages.</li><li><a>Write your First DAG</a>.</li><li><a>Deploy code to Astro</a>.</li></ul></div><div><h2>Was this page helpful?</h2><div><button>Yes</button><button>No</button></div></div><form><h2>Sign up for Developer Updates</h2><p>Get a summary of new Astro features once a month.</p><button>Submit</button><p>You can unsubscribe at any time. By proceeding you agree to our <a>Privacy Policy</a>, our <a>Website Terms</a>and to receive emails from Astronomer.</p></form><a>Edit this page</a></article><nav><a><div>Previous</div><div>With GitHub Actions</div></a><a><div>Next</div><div>Log in to Astro</div></a></nav></div><ul><a>Prerequisites</a><a>Step 1: Install the Astro CLI</a><a>Step 2: Create a Deployment</a><a>Step 3: Create an Astro project</a><a>Step 4: Deploy example DAGs to your Astro Deployment</a><a>Step 5: Trigger your DAG on Astro</a><a>Step 6: View your DAG status in the Astro UI</a><a>Next Steps</a></ul></div></div><div><div><a>Legal</a><span>·</span><a>Privacy</a><span>·</span><a>Security</a><span>·</span><a>Cookie Preferences</a></div><div><a><img/><img/></a><div>© Astronomer 2023. Various trademarks held by their respective owners.</div></div></div></div>



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow.html

Documentation Title:
Get started with Apache Airflow, Part 1: Write and run your first DAG | Astronomer Documentation

Documentation Content:
It contains information about your DAGs and is the best place to create and update Airflow connections to third-party data services.</p><p>To access the Airflow UI, open <code>http://localhost:8080/</code>in a browser and log in with <code>admin</code>for both your username and password.</p><p>The default page in the Airflow UI is the <strong>DAGs</strong>page, which shows an overview of all DAGs in your Airflow environment:</p><img/><p>Each DAG is listed with a few of its properties, including tags, owner, previous runs, schedule, timestamp of the last and next run, and the states of recent tasks. Because you haven't run any DAGs yet, the <strong>Runs</strong>and <strong>Recent Tasks</strong>sections are empty. Let's fix that!</p><h2>Step 4: Trigger a DAG run<a>​</a></h2><p>The <code>example_astronauts</code>DAG in your Astro project is a simple ETL pipeline with two tasks:</p><ul><li><code>get_astronauts</code>queries the <a>Open Notify API</a>for information about astronauts currently in space. The task returns the list of dictionaries containing the name and the spacecraft of all astronauts currently in space, which is passed to the second task in the DAG. This tutorial does not explain how to pass data between tasks, but you can learn more about it in the <a>Pass data between tasks</a>guide.</li><li><code>print_astronaut_craft</code>is a task that uses dynamic mapping to create and run a task instance for each Astronaut in space. Each of these tasks prints a statement about its mapped astronaut. Dynamic task mapping is a versatile feature of Airflow that allows you to create a variable number of tasks at runtime. This feature is covered in more depth in the <a>Create dynamic Airflow tasks</a>guide.</li></ul><p>A <strong>DAG run</strong>is an instance of a DAG running on a specific date.



Documentation Source:
docs.astronomer.io/astro/first-dag-github-actions.html

Documentation Title:
Run your first DAG with GitHub Actions | Astronomer Documentation

Documentation Content:
When the Deployment is ready, the status changes to <strong>Healthy</strong>.</p><p>For more information about possible Deployment health statuses, see <a>Deployment health</a>. Or, to learn more about how to customize your Deployment settings, see <a>Deployment settings</a>.</p></li></ol><div><div>tip</div><div><p>Astro contains an in-product tutorial that guides you through Steps 2-4 of this document and includes shortcut buttons for some key Astro actions. If you prefer to finish the quickstart this way, open your <strong>Deployments</strong>page in the Astro UI and choose your Deployment. In the <strong>Deploy your first DAG</strong>section, click <strong>With GitHub Actions</strong>and follow the steps in the window that appears.</p><p>If you don't see the <strong>Deploy your first DAG</strong>option your Deployment page, click <strong>Deploy DAGs ?</strong>to open it.</p></div></div><h2>Step 2: Fork the example project repository<a>​</a></h2><p>This repository contains an <em>Astro project</em>, which is a collection of files required for running Airflow on Astro. An Astro project includes folders for DAG files, plugins, dependencies, and more. Specifically, this Astro project includes an example DAG which, when you run it, retrieves a list of countries from an Astro S3 data store and filters the list through a data transform.</p><ol><p>Open <a>the example project repository</a>in a new tab or browser window.</p><p><strong>Choose an owner</strong>from your available options.</p><p>Keep the selection to <strong>Copy the <code>main</code>branch only</strong>.</p><p>Click <strong>Create fork</strong>.</p></ol><h2>Step 3: Set up the GitHub Actions Workflow<a>​</a></h2><p>This example repository also includes a pre-configured <a>Astronomer deploy action</a>, which you can use to set up a CI/CD deployment pipeline.



Documentation Source:
docs.astronomer.io/learn/get-started-with-airflow.html

Documentation Title:
Get started with Apache Airflow, Part 1: Write and run your first DAG | Astronomer Documentation

Documentation Content:
This view is useful for seeing DAG runs over time and troubleshooting previously failed task instances.</p><img/><p>Click on a green square to display additional information about the related task instance on the right side of the Airflow UI. The task instance view includes tabs with additional information for the task instance, such as its logs and historic runs. This is one of many available views that show details about your DAG.</p><img/><p>To access information about mapped task instances of a dynamically mapped task, click the green square of the mapping task instance and then click on <strong>[] Mapped task</strong>to view a list of all dynamically mapped task instances. Click on any entry in the list to access information about the dynamically mapped task instance.</p><img/></li><li><p>In the <strong>Grid</strong>view, click the <strong>Graph</strong>tab. This view shows task dependencies and relationships and can help you troubleshoot dependency issues. When you select a DAG run in the Grid view, the Graph tab shows the last state of each task instance in this DAG run.</p><img/></li><li><p>In the <strong>Grid</strong>view, click the <strong>Code</strong>tab to display your DAG source code. Viewing code in the Airflow UI helps you confirm which version of your code is currently running on Airflow.</p><img/></li></ol><div><div>info</div><p>While you can view DAG code within the Airflow UI, code edits must be completed in the Python file within the <code>/dags</code>folder. The displayed code updates every 30 seconds.</p></div><h2>Step 6: Write a new DAG<a>​</a></h2><p>Now that we can run DAGs and navigate the UI, let's write our own DAG and run it.</p><p>In this step, you'll write a DAG that:</p><ul><li>Retrieves the number of people currently in space from the Airflow XCom table. This table is part of the Airflow metadata database and is used to pass data between tasks and DAGs.



